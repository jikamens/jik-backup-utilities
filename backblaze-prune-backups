#!/usr/bin/env python3

import argparse
from b2api import B2API
import datetime
import logbook
import os
import psutil
from rcloneutils import (
    get_encrypted_remote,
    get_plain_remote,
    get_rclone_config,
    RcloneDecoder,
)
import resource
import sys
import threading
import time

whoami = os.path.basename(sys.argv[0])
one_day = 60 * 60 * 24
logger = None

worker_semaphore = threading.Semaphore(0)
worker_queue = []
worker_queue_semaphore = threading.Semaphore(0)
worker_queue_lock = threading.RLock()

policies = {
    # Each number here means a number of days, so for example, in the "default"
    # entry above, we save one deleted version for each day of the first week.
    # '*' means to repeat the previous number until doing so would exceed the
    # next number, so for example "default" expands to 1, 2, 3, 4, 5, 6, 7, 14,
    # 21, 28, 30, 60, etc.
    # '?' means the same as '*' but only if the file is currently undeleted, so
    # for example in "default" we only save previous versions of deleted files
    # for 365 days and then purge them.
    # If the rule doesn't end with '*' or '?', then everything older than the
    # last specified age is removed.
    'default': (1, 2, 3, 4, 5, 6, 7, '*', 30, '*', 365, '?'),
    'never': (),
    'one_week': (1, 2, 3, 4, 5, 6, 7),
    'one_month': (1, 2, 3, 4, 5, 6, 7, '*', 30),
    'three_months': (1, 2, 3, 4, 5, 6, 7, '*', 30, '*', 91),
    'six_months': (1, 2, 3, 4, 5, 6, 7, '*', 30, '*', 182),
    'one_year': (1, 2, 3, 4, 5, 6, 7, '*', 30, '*', 365),
}

path_policies = {
    'archives/': 'one_year',
    'isos/': 'one_year',
    'pictures/': 'one_year',
}


class DeleteFileException(Exception):
    pass


class PurgePolicy(object):
    now = int(time.time())

    def __init__(self, spec, oldest):
        self.original_spec = spec
        self.spec = self.expand_spec(spec, oldest)

    def expand_spec(self, original_spec, oldest):
        # Each expanded spec element is [reason, days, cutoff, must_exist]
        spec = []
        for i in range(len(original_spec)):
            orig = original_spec[i]
            if orig in ('*', '?'):
                multiplier = 2
                before = spec[-1][1]
                try:
                    after = original_spec[i + 1]
                except IndexError:
                    after = int((self.now - oldest) / one_day) + 1 + before
                while before * multiplier <= after:
                    spec.append(['{}x{}{}'.format(before, multiplier, orig),
                                 before * multiplier,
                                 self.now - one_day * before * multiplier,
                                 False if orig == '*' else True])
                    multiplier += 1
            else:
                spec.append(
                    [str(orig), orig, self.now - one_day * orig, False])
        logger.debug("Expanded spec {} to {}", original_spec, spec)
        return spec

    def apply(self, files):
        # Versions are guaranteed to be in reverse chronological order (newest
        # first) when they arrive here from b2_list_file_versions.
        if files[0]['b2_action'] == 'upload':
            is_undeleted = True
            files.pop(0)
        else:
            is_undeleted = False
        for file in files:
            if file['b2_action'] == 'hide':
                file['action'] = 'preserve'
                file['reason'] = 'hide still needed'
            else:
                file['action'] = 'delete'
                file['reason'] = ''
        # Save the newest and oldest version within each save window.
        prev_cutoff = self.now
        for cutoff in self.spec:
            in_window = list(f for f in files
                             if f['b2_action'] == 'upload' and
                             prev_cutoff >= f['timestamp'] >= cutoff[2])
            prev_cutoff = cutoff[2]
            if not in_window:
                continue
            if cutoff[3] and not is_undeleted:
                for f in in_window:
                    f['action'] = 'delete'
                    f['reason'] = cutoff[0] + ' and file is gone'
                continue
            in_window[-1]['action'] = 'preserve'
            in_window[-1]['reason'] = cutoff[0] + ' oldest'
            in_window[0]['action'] = 'preserve'
            in_window[0]['reason'] = cutoff[0] + ' newest'
        # Delete any hides that no longer need to be preserved.
        have_upload = False
        for f in reversed(files):
            if f['b2_action'] == 'upload':
                if f['action'] == 'preserve':
                    have_upload = True
            else:
                if have_upload:
                    have_upload = False
                else:
                    f['action'] = 'delete'
                    f['reason'] = 'hide no longer needed'


def find_path_policy(path):
    for policy_path, policy in path_policies.items():
        if path.startswith(policy_path):
            return policy
    return 'default'


def delete_one_file(args, account_id, api_key, decoded_path, path, timestamp,
                    file_id):
    if not clean_threads():
        raise DeleteFileException('clean_threads failed')
    if not worker_semaphore.acquire(False):
        # Don't exceed 80% of available file descriptors
        open_fds = psutil.Process().num_fds()
        max_fds = resource.getrlimit(resource.RLIMIT_NOFILE)[0]
        if open_fds / max_fds >= .8:
            logger.debug('Waiting for worker to become available')
        else:
            logger.debug('Starting new thread')
            t = threading.Thread(target=delete_worker,
                                 args=(args, account_id, api_key))
            t.start()
    else:
        worker_semaphore.release()
        logger.debug('Using existing thread')
    worker_queue_lock.acquire()
    worker_queue.append((decoded_path, path, timestamp, file_id))
    worker_queue_lock.release()
    worker_queue_semaphore.release()


def delete_worker(args, account_id, api_key):
    thread_id = threading.current_thread().ident
    if not args.dryrun:
        b2 = B2API(account_id, api_key, logger=logger)
    worker_semaphore.release()
    logger.debug('[{}] Thread active', thread_id)
    while worker_queue_semaphore.acquire():
        logger.debug('[{}] Thread working', thread_id)
        worker_semaphore.acquire()
        worker_queue_lock.acquire()
        decoded_path, path, timestamp, file_id = worker_queue.pop(0)
        worker_queue_lock.release()
        if decoded_path is None:
            logger.debug('[{}] Thread exiting', thread_id)
            return
        try:
            if args.dryrun:
                action = 'Would delete'
            else:
                b2.delete_file_version(path, file_id)
                action = 'Deleted'
            logger.debug('{} {} timestamp {} file ID {}', action,
                         decoded_path, timestamp, file_id)
        except Exception:
            logger.exception('Exception deleting version {} of {} '
                             '(encrypted: {})', file_id, decoded_path, path)
            return
        finally:
            worker_semaphore.release()
        logger.debug('[{}] Thread waiting', thread_id)


def do_one_file(args, path, versions, decoder, account_id, api_key):
    if not path:
        return True
    decoded_path = decoder.get(path)
    if decoded_path == args.stop_at:
        logger.info('Stopping at {}', decoded_path)
        return False
    if not versions or \
       (len(versions) == 1 and versions[0]['b2_action'] == 'upload'):
        logger.debug('File {} does not have any deleted versions',
                     decoded_path)
        return True
    policy_name = find_path_policy(decoded_path)
    policy = PurgePolicy(policies[policy_name],
                         min(v['timestamp'] for v in versions))
    logger.debug('Applying policy {} to {}', policy_name, decoded_path)
    policy.apply(versions)
    if args.verbose:
        print('Applied policy {} to {}:'.format(policy_name, decoded_path))
    for version in reversed(versions):
        timestamp = str(datetime.datetime.fromtimestamp(version['timestamp']))
        action = version['action']
        msg = version['action']
        if version['reason']:
            msg += ' (' + version['reason'] + ')'
        logger.debug('{} version {} result: {}',
                     decoded_path, timestamp, msg)
        if args.verbose:
            print('  {} {}'.format(timestamp, msg))
        if action == 'delete':
            delete_one_file(args, account_id, api_key, decoded_path,
                            path, timestamp, version['file_id'])
    return True


def parse_args():
    parser = argparse.ArgumentParser(description='Rule-based removal of old '
                                     'rclone-encrypted B2 backup files')
    parser.add_argument('--debug', action='store_true', default=False,
                        help='Enable debug logging')
    parser.add_argument('--verbose', action='store_true', default=False,
                        help='Enable verbose output')
    parser.add_argument('--dryrun', action='store_true', default=False,
                        help='Say what would be done without doing it')
    parser.add_argument('--start-at', action='store',
                        help='Path to start with')
    parser.add_argument('--stop-at', action='store',
                        help='Path to stop with')
    parser.add_argument('remote', nargs='?', help='Name of rclone crypt '
                        'remote backed by B2 to prune (if not specified, '
                        'found dynamically in ~/.rclone.conf)')
    return parser.parse_args()


def main():
    global logger

    args = parse_args()
    logger = logbook.Logger(whoami)
    logbook.StderrHandler(level='DEBUG' if args.debug else 'INFO').\
        push_application()

    if args.verbose:
        print('Starting at {}'.format(datetime.datetime.now()))

    config = get_rclone_config()
    if not args.remote:
        args.remote = get_encrypted_remote(config)
        if args.verbose:
            print('Using remote {}'.format(args.remote))
    b2, bucket_id = get_plain_remote(config, args.remote, logger=logger)

    logger.debug('Using bucket ID {}', bucket_id)

    ok = True
    try:
        main_loop(args, b2, bucket_id)
    except DeleteFileException:
        ok = False
    finally:
        ok = ok and clean_threads(final=True)
        if args.verbose:
            print('Finished at {}'.format(datetime.datetime.now()))
    sys.exit(0 if ok else 1)


def clean_threads(final=False):
    ok = clean_threads() if final else True
    if final:
        for t in (t for t in threading.enumerate()
                  if t != threading.current_thread()):
            logger.debug('Telling thread {} to exit'.format(t.ident))
            worker_queue_lock.acquire()
            worker_queue.append((None, None, None, None))
            worker_queue_lock.release()
            worker_queue_semaphore.release()
    for t in (t for t in threading.enumerate()
              if t != threading.current_thread()):
        if not (t.is_alive() or final):
            logger.error('Thread {} died prematurely'.format(t.ident))
            ok = False
        if not t.is_alive() or final:
            t.join()
    return ok


def main_loop(args, b2, bucket_id):
    go_on = True
    last_file_name = None
    queue = []
    last_timestamp = None
    versions = []

    account_id = b2.account_id
    api_key = b2.account_key
    decoder = RcloneDecoder(args.remote)

    if args.start_at:
        encoder = RcloneDecoder(args.remote, mode='encode')
        encoder.add(args.start_at)
        startFileName = encoder.get(args.start_at)
    else:
        startFileName = None

    for file in b2.list_file_versions(bucket_id, startFileName=startFileName):
        file_name = file['fileName']
        # We want to delete old file versions # days after they were deleted,
        # not # days after they were uploaded, so we use the timestamp of the
        # file version following each version to decide when to delete it.
        #
        # Note that the B2 API endpoint guarantees to return file versions in
        # reverse chronological order.
        timestamp = last_timestamp
        last_timestamp = int(file['uploadTimestamp'] / 1000)
        if timestamp is None:
            timestamp = last_timestamp
        decoder.add(file_name)
        if file_name != last_file_name:
            queue.append([last_file_name, versions])
            if decoder.full:
                for q in queue:
                    go_on = do_one_file(args, q[0], q[1], decoder,
                                        account_id, api_key)
                    if not go_on:
                        break
                queue = []
            if not go_on:
                break
            versions = []
            last_file_name = file_name
            last_timestamp = None
        if file['action'] not in ('upload', 'hide'):
            continue
        versions.append({
            'file_id': file['fileId'],
            'timestamp': timestamp,
            'b2_action': file['action']})

    if go_on and versions:
        queue.append([last_file_name, versions])
        for q in queue:
            if not do_one_file(args, q[0], q[1], decoder, account_id,
                               api_key):
                break


if __name__ == '__main__':
    main()
